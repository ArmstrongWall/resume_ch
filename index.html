<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<title>Johnny Wang | Robotics，Computer Vision</title>
<link href="css.css" rel="stylesheet" type="text/css" />
</head>

<body>
<div id="main">

	
		<div id="top-nav">
		
			<b>汪自强</b> | <small>Robotics Researcher</small>
	
		</div>

	
		<div id="header">
		
			<img src="images/header.png" alt="" width="770"/>
			
		</div>
		

	
		<div id="navigation" style="position: fixed">

			
			main menu
			
			<hr />
			
<a href="#Home" class="navigation">Home</a>
<a href="#Projects" class="navigation">Project Highlights</a>
<a href="#Publications" class="navigation">Publications</a>
<a href="#Rewards" class="navigation">Rewards</a>
		</div>
		

		<div id="content">
		
			<a name="Home"></a><h1>Welcome</h1>
			
			
    <p align="justify"> 
<img border="0" src="images/wzq.jpg" align="left" style="padding-right: 20px;padding-bottom: 20px"/>
机器人学爱好研究者， 研究生和工作期间主要专注在<b>机器人多传感器融合状态估计，同步建图与定位(SLAM)</b>等方面. 2018年于同济大学获得硕士学位，本科自动化，研究生控制科学与工程。旋即加入驭势科技从事机器人定位系统工作。
</p><p> 
在此展示一些我撰写的论文、演示视频、开源程序和数据集等.
</p><p> 
<b>Links: </b>
<a href="https://github.com/ArmstrongWall"><img border="0" src="images/gh.png" height="13px"/> GitHub</a>


<br/>
<b>Contact: </b>
<a href="mailto:jajuengel@gmail.com">1531651@tongji.edu.cn</a>

<br/>
</p>






<br /><br /><br /><br />

			<a name="Projects"></a><h1>Project Highlights</h1>

<h2>Stereo-VI-DSO:双目直接稀疏视觉惯性里程计</h2>
<p align="justify"><b>Stereo-VI-DSO</b> 是我主导开发的紧耦合视觉-惯性里程计(VIO)，以双目相机和IMU作为定位源，采用联合高斯牛顿优化滑窗内的所有参数
	包括所有关键帧的位姿、IMU的速度和bias、图像亮度参数以及所选像素的深度值。系统的视觉部分是将单帧静态误差的约束加入到多帧动态多视捆集调整(BA)中，
	但与基于特征点的系统不同，它直接将光度误差最小化，故称为直接法。双目的固定基线可校正尺度漂移。系统的惯性部分利用预积分法在关键帧之间积累IMU信息，
	并将其作为关键帧之间的附加约束插入到优化中。此外，我们还介绍了一个基于虚幻引擎4开发的仿真平台，它可以输出大部分用于自动驾驶领域的传感器的原始数据。
	我们在真实数据和仿真数据的基础上对该方法进行了评价，定性和定量的实验结果表明，该算法在跟踪精度和鲁棒性方面均优于Stereo-DSO。文章可见<a href="#Publications">Publications</a>。



<h2>基于LSD-SLAM的机器人路径规划和轨迹跟踪系统</h2>
<p align="justify"><b>LSD-SLAM</b> is a semi-dense, direct SLAM method I developed during my PhD at TUM. It was based on a 
<a href="https://youtu.be/LZChzEcLNzI"><img border="0" src="images/yt.png" height="13px"/> semi-dense monocular odometry approach</a>, 
and - together with colleagues and students - we extended it to 
run <a href="https://youtu.be/X0hx2vxxTMg"><img border="0" src="images/yt.png" height="13px"/> in real-time on a smartphone</a>,
run <a href="https://youtu.be/oJt3Ln8H03s"><img border="0" src="images/yt.png" height="13px"/> with stereo cameras</a>, 
run as a <a href="https://youtu.be/XSvFpPYfKWA"><img border="0" src="images/yt.png" height="13px"/> tightly coupled visual-inertial odometry</a>, 
run <a href="https://youtu.be/v0NqMm7Q6S8"><img border="0" src="images/yt.png" height="13px"/> on omnidirectional cameras</a>, 
and even to be used for <a href="https://youtu.be/fWBsDwBJD-g"><img border="0" src="images/yt.png" height="13px"/> autonomously navigating a toy quadrocopter</a>.
For the original monocular version, we published <a href="https://github.com/tum-vision/lsd_slam"><img border="0" src="images/gh.png" height="13px"/> open-source code on GitHub</a>.
<br /><i>Original Publication (ECCV)</i>: <a href="pdf/engel14eccv.pdf"><img border="0" src="images/pdf.png" height="13px"/> [pdf]</a> (see <a href="#Publications">Publications</a> for more related papers)
<br />
<br />

<h2>基于Gmapping和ROS的建图机器人</h2>
<p align="justify">
	将二维激光雷达RPLIDAR安装在四全向轮叉车机器人上，使用ROS的Gmapping完成建图与定位功能。ROS的slam_gmapping节点将订阅LaserScan节点以获取激光扫描数据，
	然后调用Rao-Blackwellized粒子滤波器的增量构建栅格地图，同时发布消息map节点以完成建图和输出机器人定位数据到tf节点。Gmapping是2007年德国弗莱堡大学的Giorgio教授发表开源的2D激光SLAM算法，
	在SLAM领域早期具有较大开创意义且被广泛运用。四全向轮叉车机器人用于仓储环境的货物运输。
</p>


<br /><br />
<br /><br />
<a name="Publications"></a><h1>Publications</h1>

<p>
	<img border="0" src="pdf_img/engel17phd.png" align="left" width="80px" style="padding-right: 10px;padding-bottom: 10px"/>
	<b>Direct Sparse Visual-Inertial Odometry with Stereo Cameras</b> (Ziqiang Wang, Chengcheng Guo), <i>No open,under review by IROS</i>, 2019.
	<br />
	<a href="https://github.com/ArmstrongWall/Supplementary_Material_to_Stereo_VI_DSO/blob/master/Supplementary%20Material%20to%20Direct%20Sparse%20Visual-Inertial%20Odometry%20with%20Stereo%20Cameras.pdf"><img border="0" src="images/pdf.png" height="13px"/> [补充材料]</a>
	<a href=http://v.youku.com/v_show/id_XNDEwNTIwMDQxNg==.html?spm=a2h3j.8428770.3416059.1"><img border="0" src="images/yt.png" height="13px"/> [视频]</a>
</p>


<p align=justify">
	<img border="0" src="pdf_img/engel2016dso.jpg" align="left" width="80px" style="padding-right: 10px;padding-bottom: 0px"/>
	<b>Wheeled Robots Path Planing and Tracking System Based on Monocular Visual SLAM</b> (Ziqiang Wang, Hegen Xu, Youwen Wan), 2018.
	<br />
	<a href="https://arxiv.org/abs/1807.06303"><img border="0" src="images/pdf.png" height="13px"/> [pdf]</a>
	<a href="https://youtu.be/C6-xwSOOdqQ"><img border="0" src="images/yt.png" height="13px"/> [video]</a>
	<a href="https://github.com/ArmstrongWall/lsd-slam"><img border="0" src="images/gh.png" height="13px"/> [code]</a>
</p>

<p>
	<img border="0" src="pdf_img/stumberg16exploration.png" align="left" width="80px" style="padding-right: 10px;padding-bottom: 20px"/>
	<b>Research and Implementation of Robot Path Planning Based on VSLAM</b> (Ziqiang Wang, Hegen Xu, Youwen Wan), In <i>International Conference on Electrical Engineering, Control and Robotics (EECR)</i>, 2017.
	<br />
	<a href="https://doi.org/10.1051/matecconf/201816006004"><img border="0" src="images/pdf.png" height="13px"/> [pdf]</a>
</p>
			<br /><br />
			<br /><br />
<a name="Rewards"></a><h1>Rewards</h1>
<p>
	<img border="0" src="pdf_img/stumberg16exploration.png" align="left" width="80px" style="padding-right: 10px;padding-bottom: 20px"/>
	<b>“华为杯”中国研究生数学建模竞赛，全国二等奖，选题为“地下物流系统的构建”, 2017.</b>
	<br />
	<a href="https://doi.org/10.1051/matecconf/201816006004"><img border="0" src="images/pdf.png" height="13px"/> [pdf]</a>
</p>

			<br />

<p align=justify">
	<img border="0" src="pdf_img/stumberg16exploration.png" align="left" width="80px" style="padding-right: 10px;padding-bottom: 20px"/>
	<b>Robomaster机甲大师赛，东部赛区二等奖, 2016.</b>
	<br />
	<a href="https://doi.org/10.1051/matecconf/201816006004"><img border="0" src="images/yt.png" height="13px"/> [video]</a>
</p>

			<br />
<p>
	<img border="0" src="pdf_img/stumberg16exploration.png" align="left" width="80px" style="padding-right: 10px;padding-bottom: 20px"/>
	<b>“飞思卡尔杯”全国大学生智能汽车竞赛，摄像头组全国总决赛第四名, 2013.</b>
		<br />
		<a href="https://doi.org/10.1051/matecconf/201816006004"><img border="0" src="images/yt.png" height="13px"/> [video]</a>
</p>
			<br />
<p>
<img border="0" src="pdf_img/stumberg16exploration.png" align="left" width="80px" style="padding-right: 10px;padding-bottom: 20px"/>
	<b>“瑞萨杯”全国大学生电子设计竞赛，东部赛区二等奖, 2013.</b>
	<br />
	<a href="https://doi.org/10.1051/matecconf/201816006004"><img border="0" src="images/yt.png" height="13px"/> [video]</a>
</p>

		</div>

		<div id="footer">

			<hr />

	Copyright 2019 | JohnnyWang | All Rights Reserved

		</div>


	
</div>

</body>

</html>
